

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import CategoricalNB
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Sample data
data = {
    'Feature1': [1, 2, 2, 1, 3, 3, 1, 2, 3],
    'Feature2': ['A', 'B', 'B', 'A', 'C', 'C', 'A', 'B', 'C'],
    'Class':    [0, 1, 1, 0, 1, 1, 0, 1, 0]
}

# Create DataFrame
df = pd.DataFrame(data)

# One-hot encode the categorical feature 'Feature2'
df_encoded = pd.get_dummies(df, columns=['Feature2'])

# Split features and target
X = df_encoded.drop('Class', axis=1)
y = df_encoded['Class']

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Naive Bayes classifier
nb_classifier = CategoricalNB()
nb_classifier.fit(X_train, y_train)

# Predict on test set
y_pred = nb_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print('Classification Report:')
print(classification_report(y_test, y_pred))
#OUTPUT

Accuracy: 1.00
Classification Report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         2

    accuracy                           1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2

